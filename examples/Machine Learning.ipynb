{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standard Data Science Workflow\n",
    "\n",
    "A train/test split of the Iris dataset followed by generating feature matrices and encoding the target classes into integers, then some simple model fitting and finally creating a confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import sqltables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some data mangling with list/dictionary data structures. \n",
    "# Helps to put the relational code below in context ;)\n",
    "\n",
    "iris = load_iris()\n",
    "feature_rows = iris[\"data\"].tolist()\n",
    "labels = [iris[\"target_names\"][t] for t in iris[\"target\"].tolist()]\n",
    "rows = [[i, t, *r] for i, (t, r) in enumerate(zip(labels, feature_rows))]\n",
    "column_names = [\"id\", \"target\", *iris[\"feature_names\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an in-memory database\n",
    "db = sqltables.Database()\n",
    "\n",
    "# Register the Python random() function for use with SQLite\n",
    "db.create_function(\"random1\", 0, random.random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Iris data into an SQL table\n",
    "input = db.load_values(rows, column_names=column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "|id|target|sepal length \\(cm\\)|sepal width \\(cm\\)|petal length \\(cm\\)|petal width \\(cm\\)|\n",
       "|-|-|-|-|-|-|\n",
       "|0|\\'setosa\\'|5\\.1|3\\.5|1\\.4|0\\.2|\n",
       "|1|\\'setosa\\'|4\\.9|3\\.0|1\\.4|0\\.2|\n",
       "|2|\\'setosa\\'|4\\.7|3\\.2|1\\.3|0\\.2|\n",
       "|3|\\'setosa\\'|4\\.6|3\\.1|1\\.5|0\\.2|\n",
       "|4|\\'setosa\\'|5\\.0|3\\.6|1\\.4|0\\.2|\n",
       "|5|\\'setosa\\'|5\\.4|3\\.9|1\\.7|0\\.4|\n",
       "|6|\\'setosa\\'|4\\.6|3\\.4|1\\.4|0\\.3|\n",
       "|7|\\'setosa\\'|5\\.0|3\\.4|1\\.5|0\\.2|\n",
       "|8|\\'setosa\\'|4\\.4|2\\.9|1\\.4|0\\.2|\n",
       "|9|\\'setosa\\'|4\\.9|3\\.1|1\\.5|0\\.1|\n",
       "|10|\\'setosa\\'|5\\.4|3\\.7|1\\.5|0\\.2|\n",
       "|11|\\'setosa\\'|4\\.8|3\\.4|1\\.6|0\\.2|\n",
       "|12|\\'setosa\\'|4\\.8|3\\.0|1\\.4|0\\.1|\n",
       "|13|\\'setosa\\'|4\\.3|3\\.0|1\\.1|0\\.1|\n",
       "|14|\\'setosa\\'|5\\.8|4\\.0|1\\.2|0\\.2|\n",
       "|15|\\'setosa\\'|5\\.7|4\\.4|1\\.5|0\\.4|\n",
       "|...|...|...|...|...|...|\n"
      ],
      "text/plain": [
       "<sqltables.sqltables.Table at 0x111b16790>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display implemented through the _repr_markdown_() method on Table\n",
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "|id|subset|\n",
       "|-|-|\n",
       "|0|\\'train\\'|\n",
       "|1|\\'train\\'|\n",
       "|2|\\'train\\'|\n",
       "|3|\\'test\\'|\n",
       "|4|\\'train\\'|\n",
       "|5|\\'train\\'|\n",
       "|6|\\'train\\'|\n",
       "|7|\\'test\\'|\n",
       "|8|\\'test\\'|\n",
       "|9|\\'train\\'|\n",
       "|10|\\'test\\'|\n",
       "|11|\\'train\\'|\n",
       "|12|\\'test\\'|\n",
       "|13|\\'test\\'|\n",
       "|14|\\'train\\'|\n",
       "|15|\\'train\\'|\n",
       "|...|...|\n"
      ],
      "text/plain": [
       "<sqltables.sqltables.Table at 0x12550a820>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create train/test split\n",
    "\n",
    "random.seed(23)\n",
    "subsets = input.table(\"\"\"\n",
    "select \n",
    "    id, \n",
    "    case random1() <= 0.25\n",
    "        when true then 'test' \n",
    "        else 'train' \n",
    "    end as subset \n",
    "    from _\n",
    "\"\"\")\n",
    "subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "|subset|count\\(\\*\\)|\n",
       "|-|-|\n",
       "|\\'test\\'|36|\n",
       "|\\'train\\'|114|\n"
      ],
      "text/plain": [
       "<sqltables.sqltables.Table at 0x125530460>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check\n",
    "subsets.view(\"select subset, count(*) from _ group by subset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to create a feature matrix from an Iris dataset\n",
    "\n",
    "def extract_feature_matrix(dataset):\n",
    "    features = dataset.view(\"\"\"\n",
    "    select \n",
    "        \"sepal length (cm)\",\n",
    "        \"sepal width (cm)\",\n",
    "        \"petal length (cm)\",\n",
    "        \"petal width (cm)\"\n",
    "    from _\n",
    "    order by id\n",
    "    \"\"\")\n",
    "    return np.array(list(features))\n",
    "\n",
    "def extract_target_indices(dataset, target_encoding):\n",
    "    data_encoded = dataset.view(\"\"\"\n",
    "        select encoding from _ join target_encoding using (target)\n",
    "        order by id\n",
    "    \"\"\", bindings={\"target_encoding\": target_encoding})\n",
    "    return np.array([enc for [enc] in data_encoded])\n",
    "\n",
    "def extract_ids(dataset):\n",
    "    return [id for [id] in dataset.view(\"select id from _ order by id\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "|target|encoding|\n",
       "|-|-|\n",
       "|\\'setosa\\'|1|\n",
       "|\\'versicolor\\'|2|\n",
       "|\\'virginica\\'|3|\n"
      ],
      "text/plain": [
       "<sqltables.sqltables.Table at 0x111ab8c70>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dictionary for the class labels\n",
    "\n",
    "target_encoding = input.table(\"\"\"\n",
    "    select target, row_number() over (order by target) as encoding\n",
    "    from (select distinct target from _)\n",
    "\"\"\")\n",
    "target_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': (114, 4), 'test': (36, 4)}\n",
      "{'train': (114,), 'test': (36,)}\n",
      "{'train': 114, 'test': 36}\n"
     ]
    }
   ],
   "source": [
    "# Create dictionaries ids, X and y with ids, feature and target data \n",
    "# for each subset. The ids can be used for example to link the predictions\n",
    "# of the model back to the relational data.\n",
    "# We are leaving the relational domain here and enter the number\n",
    "# crunching realm.\n",
    "\n",
    "X = {}\n",
    "y = {}\n",
    "ids = {}\n",
    "\n",
    "for [subset] in subsets.view(\"select distinct subset from _\"):\n",
    "    bindings = {\"subsets\": subsets}\n",
    "    subset_data = input.table(\"\"\"\n",
    "        select * from _ join subsets using (id) \n",
    "        where subset = ?\n",
    "        order by id\n",
    "    \"\"\", [subset], bindings=bindings)\n",
    "    X[subset] = extract_feature_matrix(subset_data)\n",
    "    y[subset] = extract_target_indices(subset_data, target_encoding)\n",
    "    ids[subset] = extract_ids(subset_data)\n",
    "\n",
    "print({k: v.shape for k, v in X.items()})\n",
    "print({k: v.shape for k, v in y.items()})\n",
    "print({k: len(v) for k, v in ids.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "|id|prediction|\n",
       "|-|-|\n",
       "|0|\\'setosa\\'|\n",
       "|1|\\'setosa\\'|\n",
       "|2|\\'setosa\\'|\n",
       "|3|\\'setosa\\'|\n",
       "|4|\\'setosa\\'|\n",
       "|5|\\'setosa\\'|\n",
       "|6|\\'setosa\\'|\n",
       "|7|\\'setosa\\'|\n",
       "|8|\\'setosa\\'|\n",
       "|9|\\'setosa\\'|\n",
       "|10|\\'setosa\\'|\n",
       "|11|\\'setosa\\'|\n",
       "|12|\\'setosa\\'|\n",
       "|13|\\'setosa\\'|\n",
       "|14|\\'setosa\\'|\n",
       "|15|\\'setosa\\'|\n",
       "|...|...|\n"
      ],
      "text/plain": [
       "<sqltables.sqltables.Table at 0x125554cd0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit a model and make some predictions. \n",
    "# Mangle the predictions back into a table.\n",
    "\n",
    "classifier = LogisticRegression(\n",
    "    multi_class='multinomial',  solver=\"newton-cg\"\n",
    ")\n",
    "classifier.fit(X[\"train\"], y[\"train\"])\n",
    "input_ids = [id for [id] in input.view(\"select id from _ order by id\")]\n",
    "y_hat = classifier.predict(extract_feature_matrix(input)).tolist()\n",
    "rows = [[id, y1] for id, y1 in zip(input_ids, y_hat)]\n",
    "predictions_encoded = db.create_table(\n",
    "    values=rows, column_names=[\"id\", \"encoding\"])\n",
    "\n",
    "# Back into the relational world\n",
    "predictions = predictions_encoded.table(\"\"\"\n",
    "    select id, target_encoding.target as prediction \n",
    "    from _ \n",
    "    join target_encoding using (encoding)\n",
    "    \"\"\", bindings={\"target_encoding\": target_encoding})\n",
    "\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "|id|target|sepal length \\(cm\\)|sepal width \\(cm\\)|petal length \\(cm\\)|petal width \\(cm\\)|prediction|subset|\n",
       "|-|-|-|-|-|-|-|-|\n",
       "|0|\\'setosa\\'|5\\.1|3\\.5|1\\.4|0\\.2|\\'setosa\\'|\\'train\\'|\n",
       "|1|\\'setosa\\'|4\\.9|3\\.0|1\\.4|0\\.2|\\'setosa\\'|\\'train\\'|\n",
       "|2|\\'setosa\\'|4\\.7|3\\.2|1\\.3|0\\.2|\\'setosa\\'|\\'train\\'|\n",
       "|3|\\'setosa\\'|4\\.6|3\\.1|1\\.5|0\\.2|\\'setosa\\'|\\'test\\'|\n",
       "|4|\\'setosa\\'|5\\.0|3\\.6|1\\.4|0\\.2|\\'setosa\\'|\\'train\\'|\n",
       "|5|\\'setosa\\'|5\\.4|3\\.9|1\\.7|0\\.4|\\'setosa\\'|\\'train\\'|\n",
       "|6|\\'setosa\\'|4\\.6|3\\.4|1\\.4|0\\.3|\\'setosa\\'|\\'train\\'|\n",
       "|7|\\'setosa\\'|5\\.0|3\\.4|1\\.5|0\\.2|\\'setosa\\'|\\'test\\'|\n",
       "|8|\\'setosa\\'|4\\.4|2\\.9|1\\.4|0\\.2|\\'setosa\\'|\\'test\\'|\n",
       "|9|\\'setosa\\'|4\\.9|3\\.1|1\\.5|0\\.1|\\'setosa\\'|\\'train\\'|\n",
       "|10|\\'setosa\\'|5\\.4|3\\.7|1\\.5|0\\.2|\\'setosa\\'|\\'test\\'|\n",
       "|11|\\'setosa\\'|4\\.8|3\\.4|1\\.6|0\\.2|\\'setosa\\'|\\'train\\'|\n",
       "|12|\\'setosa\\'|4\\.8|3\\.0|1\\.4|0\\.1|\\'setosa\\'|\\'test\\'|\n",
       "|13|\\'setosa\\'|4\\.3|3\\.0|1\\.1|0\\.1|\\'setosa\\'|\\'test\\'|\n",
       "|14|\\'setosa\\'|5\\.8|4\\.0|1\\.2|0\\.2|\\'setosa\\'|\\'train\\'|\n",
       "|15|\\'setosa\\'|5\\.7|4\\.4|1\\.5|0\\.4|\\'setosa\\'|\\'train\\'|\n",
       "|...|...|...|...|...|...|...|...|\n"
      ],
      "text/plain": [
       "<sqltables.sqltables.Table at 0x12550a880>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aggregate data into a single table for convenient analysis\n",
    "result = input.table(\"\"\"\n",
    "    select * \n",
    "    from _ \n",
    "    join predictions using (id)\n",
    "    join subsets using (id)\n",
    "    \"\"\", bindings={\"predictions\": predictions, \"subsets\": subsets})\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "|subset|target|prediction|count|\n",
       "|-|-|-|-|\n",
       "|\\'test\\'|\\'setosa\\'|\\'setosa\\'|14|\n",
       "|\\'test\\'|\\'versicolor\\'|\\'versicolor\\'|10|\n",
       "|\\'test\\'|\\'versicolor\\'|\\'virginica\\'|1|\n",
       "|\\'test\\'|\\'virginica\\'|\\'virginica\\'|11|\n",
       "|\\'train\\'|\\'setosa\\'|\\'setosa\\'|36|\n",
       "|\\'train\\'|\\'versicolor\\'|\\'versicolor\\'|37|\n",
       "|\\'train\\'|\\'versicolor\\'|\\'virginica\\'|2|\n",
       "|\\'train\\'|\\'virginica\\'|\\'virginica\\'|39|\n"
      ],
      "text/plain": [
       "<sqltables.sqltables.Table at 0x1255306d0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confusion matrix\n",
    "\n",
    "result.view(\"\"\"\n",
    "select\n",
    "    subset, target, prediction, count(*) as count \n",
    "from _ \n",
    "group by subset, target, prediction \n",
    "order by subset, target, prediction\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "|id|target|sepal length \\(cm\\)|sepal width \\(cm\\)|petal length \\(cm\\)|petal width \\(cm\\)|prediction|subset|\n",
       "|-|-|-|-|-|-|-|-|\n",
       "|70|\\'versicolor\\'|5\\.9|3\\.2|4\\.8|1\\.8|\\'virginica\\'|\\'train\\'|\n",
       "|77|\\'versicolor\\'|6\\.7|3\\.0|5\\.0|1\\.7|\\'virginica\\'|\\'train\\'|\n",
       "|83|\\'versicolor\\'|6\\.0|2\\.7|5\\.1|1\\.6|\\'virginica\\'|\\'test\\'|\n"
      ],
      "text/plain": [
       "<sqltables.sqltables.Table at 0x125530520>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect\n",
    "\n",
    "result.view(\"select * from _ where target != prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "|id|target|sepal length \\(cm\\)|sepal width \\(cm\\)|petal length \\(cm\\)|petal width \\(cm\\)|prediction|subset|\n",
       "|-|-|-|-|-|-|-|-|\n",
       "|0|\\'setosa\\'|5\\.1|3\\.5|1\\.4|0\\.2|\\'setosa\\'|\\'train\\'|\n",
       "|1|\\'setosa\\'|4\\.9|3\\.0|1\\.4|0\\.2|\\'setosa\\'|\\'train\\'|\n",
       "|2|\\'setosa\\'|4\\.7|3\\.2|1\\.3|0\\.2|\\'setosa\\'|\\'train\\'|\n",
       "|3|\\'setosa\\'|4\\.6|3\\.1|1\\.5|0\\.2|\\'setosa\\'|\\'test\\'|\n",
       "|4|\\'setosa\\'|5\\.0|3\\.6|1\\.4|0\\.2|\\'setosa\\'|\\'train\\'|\n",
       "|5|\\'setosa\\'|5\\.4|3\\.9|1\\.7|0\\.4|\\'setosa\\'|\\'train\\'|\n",
       "|6|\\'setosa\\'|4\\.6|3\\.4|1\\.4|0\\.3|\\'setosa\\'|\\'train\\'|\n",
       "|7|\\'setosa\\'|5\\.0|3\\.4|1\\.5|0\\.2|\\'setosa\\'|\\'test\\'|\n",
       "|8|\\'setosa\\'|4\\.4|2\\.9|1\\.4|0\\.2|\\'setosa\\'|\\'test\\'|\n",
       "|9|\\'setosa\\'|4\\.9|3\\.1|1\\.5|0\\.1|\\'setosa\\'|\\'train\\'|\n",
       "|10|\\'setosa\\'|5\\.4|3\\.7|1\\.5|0\\.2|\\'setosa\\'|\\'test\\'|\n",
       "|11|\\'setosa\\'|4\\.8|3\\.4|1\\.6|0\\.2|\\'setosa\\'|\\'train\\'|\n",
       "|12|\\'setosa\\'|4\\.8|3\\.0|1\\.4|0\\.1|\\'setosa\\'|\\'test\\'|\n",
       "|13|\\'setosa\\'|4\\.3|3\\.0|1\\.1|0\\.1|\\'setosa\\'|\\'test\\'|\n",
       "|14|\\'setosa\\'|5\\.8|4\\.0|1\\.2|0\\.2|\\'setosa\\'|\\'train\\'|\n",
       "|15|\\'setosa\\'|5\\.7|4\\.4|1\\.5|0\\.4|\\'setosa\\'|\\'train\\'|\n",
       "|...|...|...|...|...|...|...|...|\n"
      ],
      "text/plain": [
       "<sqltables.sqltables.Table at 0x12555fd90>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write the output to the file result.sqlite3\n",
    "\n",
    "output_db = sqltables.Database(\"result.sqlite3\")\n",
    "it = iter(result)\n",
    "output_db.create_table(values=it, column_names=it.column_names, name=\"result\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
